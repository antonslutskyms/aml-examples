{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Pipeline Displays the following capabilities\n",
    "- Impute Missing Data\n",
    "- Split Data into Train/Test partitions\n",
    "- Train a Machine Learning Model using optimized hyperparameter sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Impute Missing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_src/impute_missing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_src/impute_missing.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--clean_data_csv\", type=str, help=\"name of inputed data\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "\n",
    "    credit_df = pd.read_csv(args.data, header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    credit_df['AGE'].fillna(credit_df['AGE'].mean(), inplace = True)\n",
    "\n",
    "    os.makedirs(args.clean_data_csv, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(os.getcwd(), args.clean_data_csv, \"imputed_data.csv\")\n",
    "\n",
    "    credit_df.to_csv(out_path, index=False, header=True)\n",
    "\n",
    "\n",
    "    credit_df_chk = pd.read_csv(args.data, header=1, index_col=0)\n",
    "\n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting impute_missing.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile impute_missing.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: impute_missing\n",
    "code: local_src\n",
    "command: >-\n",
    "  python impute_missing.py \n",
    "  --data ${{inputs.data}} \n",
    "  --clean_data_csv ${{inputs.clean_data_csv}}\n",
    "inputs:\n",
    "  data: \n",
    "    type: uri_file\n",
    "  clean_data_csv: \n",
    "    type: string\n",
    "outputs:\n",
    "  clean_data_csv:\n",
    "    type: uri_file\n",
    "    mode: rw_mount\n",
    "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
    "compute: azureml:cpu-cluster\n",
    "display_name: sweep_clean_data\n",
    "experiment_name: aml-examples\n",
    "description: Train a Machine Learning model using a workspace Data asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$schema\": \"https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\",\n",
      "  \"code\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/codes/6b3a0174-3afa-417b-ae4c-dd4669104221/versions/1\",\n",
      "  \"command\": \"python impute_missing.py  --data ${{inputs.data}}  --clean_data_csv ${{inputs.clean_data_csv}}\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:33:48.110194+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-11-09T17:33:48.220936+00:00\",\n",
      "    \"last_modified_by\": \"Anton Slutsky\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Train a Machine Learning model using a workspace Data asset.\",\n",
      "  \"display_name\": \"sweep_clean_data\",\n",
      "  \"environment\": \"azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/components/impute_missing/versions/2023-11-09-17-33-46-5112416\",\n",
      "  \"inputs\": {\n",
      "    \"clean_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"data\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"uri_file\"\n",
      "    }\n",
      "  },\n",
      "  \"is_deterministic\": true,\n",
      "  \"name\": \"impute_missing\",\n",
      "  \"outputs\": {\n",
      "    \"clean_data_csv\": {\n",
      "      \"type\": \"uri_file\"\n",
      "    }\n",
      "  },\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1\n",
      "  },\n",
      "  \"type\": \"command\",\n",
      "  \"version\": \"2023-11-09-17-33-46-5112416\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading local_src (0.01 MBs):   0%|          | 0/11188 [00:00<?, ?it/s]\n",
      "Uploading local_src (0.01 MBs):  87%|########6 | 9699/11188 [00:00<00:00, 85393.38it/s]\n",
      "Uploading local_src (0.01 MBs): 100%|##########| 11188/11188 [00:00<00:00, 96409.69it/s]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!az ml component create -f impute_missing.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Data Splitter Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_src/split_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_src/split_data.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import mlflow\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--train_data_csv\", type=str, help=\"name of train data\")\n",
    "    parser.add_argument(\"--test_data_csv\", type=str, help=\"name of test data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    print(\"Dir:\\n\", listdir(args.data))\n",
    "\n",
    "    credit_df = pd.read_csv(f\"{args.data}/imputed_data.csv\", header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    credit_train_df, credit_test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "\n",
    "    os.makedirs(args.train_data_csv, exist_ok=True)\n",
    "    os.makedirs(args.test_data_csv, exist_ok=True)\n",
    "\n",
    "    credit_train_df.to_csv(os.path.join(os.getcwd(), args.train_data_csv, \"data.csv\"), index=False)\n",
    "\n",
    "    credit_test_df.to_csv(os.path.join(os.getcwd(), args.test_data_csv, \"data.csv\"), index=False)\n",
    "\n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Data Splitter Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_src/split_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_src/split_data.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import mlflow\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--train_data_csv\", type=str, help=\"name of train data\")\n",
    "    parser.add_argument(\"--test_data_csv\", type=str, help=\"name of test data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    print(\"Dir:\\n\", listdir(args.data))\n",
    "\n",
    "\n",
    "\n",
    "    credit_df = pd.read_csv(f\"{args.data}/imputed_data.csv\", header=0, index_col=0)\n",
    "\n",
    "    print(\"Headers:::::::\", credit_df.columns)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    credit_train_df, credit_test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "\n",
    "    os.makedirs(args.train_data_csv, exist_ok=True)\n",
    "    os.makedirs(args.test_data_csv, exist_ok=True)\n",
    "\n",
    "    credit_train_df.to_csv(os.path.join(os.getcwd(), args.train_data_csv, \"data.csv\"), index=False)\n",
    "\n",
    "    credit_test_df.to_csv(os.path.join(os.getcwd(), args.test_data_csv, \"data.csv\"), index=False)\n",
    "\n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting split_data.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile split_data.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: sweep_clean_data\n",
    "code: local_src\n",
    "command: >-\n",
    "  python split_data.py \n",
    "  --data ${{inputs.data}} \n",
    "  --test_train_ratio ${{inputs.test_train_ratio}} \n",
    "  --train_data_csv ${{outputs.train_data_csv}}\n",
    "  --test_data_csv ${{outputs.test_data_csv}}\n",
    "inputs:\n",
    "  data: \n",
    "    type: uri_file\n",
    "  test_train_ratio: \n",
    "    type: number\n",
    "  train_data_csv: \n",
    "    type: string\n",
    "  test_data_csv: \n",
    "    type: string\n",
    "outputs:\n",
    "  train_data_csv:\n",
    "    type: uri_folder\n",
    "    mode: rw_mount\n",
    "  test_data_csv:\n",
    "    type: uri_folder\n",
    "    mode: rw_mount\n",
    "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
    "compute: azureml:cpu-cluster\n",
    "display_name: sweep_clean_data\n",
    "experiment_name: aml-examples\n",
    "description: Train a Machine Learning model using a workspace Data asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading local_src (0.01 MBs):   0%|          | 0/11129 [00:00<?, ?it/s]\n",
      "Uploading local_src (0.01 MBs):  46%|####5     | 5107/11129 [00:00<00:00, 47927.56it/s]\n",
      "Uploading local_src (0.01 MBs): 100%|##########| 11129/11129 [00:00<00:00, 72830.32it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \"$schema\": \"https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\",\n",
      "  \"code\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/codes/33a37ca7-0488-4bff-90e6-30e9e7e60eaf/versions/1\",\n",
      "  \"command\": \"python split_data.py  --data ${{inputs.data}}  --test_train_ratio ${{inputs.test_train_ratio}}  --train_data_csv ${{outputs.train_data_csv}} --test_data_csv ${{outputs.test_data_csv}}\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:33:56.339110+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-11-09T17:33:56.466059+00:00\",\n",
      "    \"last_modified_by\": \"Anton Slutsky\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Train a Machine Learning model using a workspace Data asset.\",\n",
      "  \"display_name\": \"sweep_clean_data\",\n",
      "  \"environment\": \"azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/components/sweep_clean_data/versions/2023-11-09-17-33-55-1762190\",\n",
      "  \"inputs\": {\n",
      "    \"data\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"uri_file\"\n",
      "    },\n",
      "    \"test_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_train_ratio\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"train_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"is_deterministic\": true,\n",
      "  \"name\": \"sweep_clean_data\",\n",
      "  \"outputs\": {\n",
      "    \"test_data_csv\": {\n",
      "      \"type\": \"uri_folder\"\n",
      "    },\n",
      "    \"train_data_csv\": {\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1\n",
      "  },\n",
      "  \"type\": \"command\",\n",
      "  \"version\": \"2023-11-09-17-33-55-1762190\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!az ml component create -f split_data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting split_data.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile split_data.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: sweep_clean_data\n",
    "code: local_src\n",
    "command: >-\n",
    "  python split_data.py \n",
    "  --data ${{inputs.data}} \n",
    "  --test_train_ratio ${{inputs.test_train_ratio}} \n",
    "  --train_data_csv ${{outputs.train_data_csv}}\n",
    "  --test_data_csv ${{outputs.test_data_csv}}\n",
    "inputs:\n",
    "  data: \n",
    "    type: uri_file\n",
    "  test_train_ratio: \n",
    "    type: number\n",
    "  train_data_csv: \n",
    "    type: string\n",
    "  test_data_csv: \n",
    "    type: string\n",
    "outputs:\n",
    "  train_data_csv:\n",
    "    type: uri_folder\n",
    "    mode: rw_mount\n",
    "  test_data_csv:\n",
    "    type: uri_folder\n",
    "    mode: rw_mount\n",
    "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
    "compute: azureml:cpu-cluster\n",
    "display_name: sweep_clean_data\n",
    "experiment_name: aml-examples\n",
    "description: Train a Machine Learning model using a workspace Data asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$schema\": \"https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\",\n",
      "  \"code\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/codes/33a37ca7-0488-4bff-90e6-30e9e7e60eaf/versions/1\",\n",
      "  \"command\": \"python split_data.py  --data ${{inputs.data}}  --test_train_ratio ${{inputs.test_train_ratio}}  --train_data_csv ${{outputs.train_data_csv}} --test_data_csv ${{outputs.test_data_csv}}\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:34:04.530053+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-11-09T17:34:04.644500+00:00\",\n",
      "    \"last_modified_by\": \"Anton Slutsky\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Train a Machine Learning model using a workspace Data asset.\",\n",
      "  \"display_name\": \"sweep_clean_data\",\n",
      "  \"environment\": \"azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/components/sweep_clean_data/versions/2023-11-09-17-34-03-2840926\",\n",
      "  \"inputs\": {\n",
      "    \"data\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"uri_file\"\n",
      "    },\n",
      "    \"test_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_train_ratio\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"train_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"is_deterministic\": true,\n",
      "  \"name\": \"sweep_clean_data\",\n",
      "  \"outputs\": {\n",
      "    \"test_data_csv\": {\n",
      "      \"type\": \"uri_folder\"\n",
      "    },\n",
      "    \"train_data_csv\": {\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1\n",
      "  },\n",
      "  \"type\": \"command\",\n",
      "  \"version\": \"2023-11-09-17-34-03-2840926\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!az ml component create -f split_data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_src/train.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "\n",
    "    print(\"Dir:\", listdir(args.data))\n",
    "\n",
    "    \n",
    "    credit_df = pd.read_csv(f\"{args.data}/data.csv\", header=0, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    #Split train and test datasets\n",
    "    train_df, test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "    ####################\n",
    "    #</prepare the data>\n",
    "    ####################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "\n",
    "\n",
    "    print(\"Columns:\\n\", list(train_df.columns))\n",
    "\n",
    "    # Extracting the label column\n",
    "    y_train = train_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_train = train_df.values\n",
    "\n",
    "    # Extracting the label column\n",
    "    y_test = test_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_test = test_df.values\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ####################\n",
    "    # Log classifier accuracy\n",
    "    ####################\n",
    "\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(accuracy))\n",
    "    mlflow.log_metric('accuracy', float(accuracy))\n",
    "    # mlflow.log_metric('accuracy', 1.0)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    ###################\n",
    "    #</train the model>\n",
    "    ###################\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # Registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        registered_model_name=args.registered_model_name,\n",
    "        artifact_path=args.registered_model_name,\n",
    "    )\n",
    "\n",
    "    # Saving the model to a file\n",
    "    mlflow.sklearn.save_model(\n",
    "        sk_model=clf,\n",
    "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
    "    )\n",
    "    ###########################\n",
    "    #</save and register model>\n",
    "    ###########################\n",
    "    \n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.yaml\n",
    "# <component>\n",
    "name: sweep_train_credit_defaults_component\n",
    "display_name: Sweep Train Credit Defaults Component\n",
    "# version: 1 # Not specifying a version will automatically update the version\n",
    "type: command\n",
    "inputs:\n",
    "  train_data_csv: \n",
    "    type: uri_folder\n",
    "    mode: ro_mount\n",
    "  test_data_csv: \n",
    "    type: uri_file\n",
    "    mode: ro_mount\n",
    "  learning_rate:\n",
    "    type: number     \n",
    "  registered_model_name:\n",
    "    type: string\n",
    "outputs:\n",
    "  model:\n",
    "    type: uri_folder\n",
    "code: local_src\n",
    "environment:\n",
    "  # for this step, we'll use an AzureML curate environment\n",
    "  azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
    "command: >-\n",
    "  python train.py \n",
    "  --data ${{inputs.train_data_csv}}  \n",
    "  --learning_rate ${{inputs.learning_rate}}\n",
    "  --registered_model_name ${{inputs.registered_model_name}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"code\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/codes/33a37ca7-0488-4bff-90e6-30e9e7e60eaf/versions/1\",\n",
      "  \"command\": \"python train.py  --data ${{inputs.train_data_csv}}   --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}} \",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:34:12.485121+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-11-09T17:34:12.607847+00:00\",\n",
      "    \"last_modified_by\": \"Anton Slutsky\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"display_name\": \"Sweep Train Credit Defaults Component\",\n",
      "  \"environment\": \"azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/components/sweep_train_credit_defaults_component/versions/2023-11-09-17-34-11-1892969\",\n",
      "  \"inputs\": {\n",
      "    \"learning_rate\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"registered_model_name\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"uri_file\"\n",
      "    },\n",
      "    \"train_data_csv\": {\n",
      "      \"optional\": false,\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"is_deterministic\": true,\n",
      "  \"name\": \"sweep_train_credit_defaults_component\",\n",
      "  \"outputs\": {\n",
      "    \"model\": {\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1\n",
      "  },\n",
      "  \"type\": \"command\",\n",
      "  \"version\": \"2023-11-09-17-34-11-1892969\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!az ml component create -f train.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sweep_pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile sweep_pipeline.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "name: pipeline_inpute_and_hyper_sweep_[RANDID]\n",
    "display_name: pipeline_inpute_and_hyper_sweep_XX\n",
    "description: Tune hyperparameters using TF component\n",
    "settings:\n",
    "    default_compute: azureml:cpu-cluster\n",
    "\n",
    "jobs:\n",
    "  impute_missing:\n",
    "    type: command\n",
    "    inputs:\n",
    "      data: \n",
    "        type: uri_file\n",
    "        path: azureml:credit_cards@latest\n",
    "      clean_data_csv: clean \n",
    "    outputs:\n",
    "      clean_data_csv: \n",
    "        mode: upload\n",
    "    code: local_src\n",
    "    environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\n",
    "    compute: azureml:cpu-cluster\n",
    "    command: >-\n",
    "      python impute_missing.py \n",
    "      --data ${{inputs.data}} \n",
    "      --clean_data_csv ${{outputs.clean_data_csv}}\n",
    "\n",
    "  split_data:\n",
    "    type: command\n",
    "    inputs:\n",
    "      data: ${{parent.jobs.impute_missing.outputs.clean_data_csv}}\n",
    "      test_train_ratio: 0.25\n",
    "      train_data_csv: train \n",
    "      test_data_csv: test\n",
    "    outputs:\n",
    "      train_data_csv: \n",
    "        mode: upload\n",
    "      test_data_csv: \n",
    "        mode: upload\n",
    "    code: local_src\n",
    "    environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\n",
    "    compute: azureml:cpu-cluster\n",
    "    command: >-\n",
    "      python split_data.py \n",
    "      --data ${{inputs.data}} \n",
    "      --test_train_ratio ${{inputs.test_train_ratio}} \n",
    "      --train_data_csv ${{outputs.train_data_csv}}\n",
    "      --test_data_csv ${{outputs.test_data_csv}}\n",
    "\n",
    "  sweep_step:\n",
    "    type: sweep\n",
    "    trial: train.yaml\n",
    "    inputs:\n",
    "      train_data_csv: ${{parent.jobs.split_data.outputs.train_data_csv}}\n",
    "      test_data_csv: ${{parent.jobs.split_data.outputs.test_data_csv}}\n",
    "      registered_model_name: sweeped_credit_default_model\n",
    "    sampling_algorithm: random\n",
    "    search_space:\n",
    "      learning_rate: \n",
    "        type: uniform\n",
    "        min_value: 0.1\n",
    "        max_value: 3.0\n",
    "    objective:\n",
    "      goal: maximize\n",
    "      primary_metric: accuracy\n",
    "    limits:\n",
    "      max_total_trials: 4\n",
    "      max_concurrent_trials: 2\n",
    "      timeout: 3600\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "yaml = open(\"sweep_pipeline.yaml\").read().replace(\"[RANDID]\", str(random.randint(0, 1000000)))\n",
    "\n",
    "with open(\"sweep_pipeline.yaml\", \"w\") as out:\n",
    "    out.write(yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$schema\": \"https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:34:30.537742+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\",\n",
      "    \"last_modified_at\": \"2023-11-09T17:34:30.691184+00:00\",\n",
      "    \"last_modified_by\": \"Anton Slutsky\",\n",
      "    \"last_modified_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Tune hyperparameters using TF component\",\n",
      "  \"display_name\": \"pipeline_inpute_and_hyper_sweep_XX\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/components/pipeline_inpute_and_hyper_sweep_559086/versions/1\",\n",
      "  \"is_deterministic\": false,\n",
      "  \"name\": \"pipeline_inpute_and_hyper_sweep_559086\",\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"type\": \"pipeline\",\n",
      "  \"version\": \"1\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "!az ml component create -f sweep_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-09T17:34:48.560430+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Tune hyperparameters using TF component\",\n",
      "  \"display_name\": \"pipeline_inpute_and_hyper_sweep_XX\",\n",
      "  \"experiment_name\": \"aml-examples\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/jobs/pipeline_inpute_and_hyper_sweep_559086\",\n",
      "  \"jobs\": {\n",
      "    \"impute_missing\": {\n",
      "      \"component\": \"azureml:azureml_anonymous:f89e1f11-9fc5-43d7-b01c-823af0ebbf5b\",\n",
      "      \"compute\": \"azureml:cpu-cluster\",\n",
      "      \"inputs\": {\n",
      "        \"clean_data_csv\": \"clean\",\n",
      "        \"data\": {\n",
      "          \"path\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial/data/credit_cards/versions/3\",\n",
      "          \"type\": \"uri_file\"\n",
      "        }\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"clean_data_csv\": {\n",
      "          \"mode\": \"upload\",\n",
      "          \"type\": \"uri_folder\"\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"command\"\n",
      "    },\n",
      "    \"split_data\": {\n",
      "      \"component\": \"azureml:azureml_anonymous:a020576c-cc5b-41c2-b82e-045cd66afffd\",\n",
      "      \"compute\": \"azureml:cpu-cluster\",\n",
      "      \"inputs\": {\n",
      "        \"data\": {\n",
      "          \"path\": \"${{parent.jobs.impute_missing.outputs.clean_data_csv}}\"\n",
      "        },\n",
      "        \"test_data_csv\": \"test\",\n",
      "        \"test_train_ratio\": \"0.25\",\n",
      "        \"train_data_csv\": \"train\"\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"test_data_csv\": {\n",
      "          \"mode\": \"upload\",\n",
      "          \"type\": \"uri_folder\"\n",
      "        },\n",
      "        \"train_data_csv\": {\n",
      "          \"mode\": \"upload\",\n",
      "          \"type\": \"uri_folder\"\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"command\"\n",
      "    },\n",
      "    \"sweep_step\": {\n",
      "      \"inputs\": {\n",
      "        \"registered_model_name\": \"sweeped_credit_default_model\",\n",
      "        \"test_data_csv\": {\n",
      "          \"path\": \"${{parent.jobs.split_data.outputs.test_data_csv}}\"\n",
      "        },\n",
      "        \"train_data_csv\": {\n",
      "          \"path\": \"${{parent.jobs.split_data.outputs.train_data_csv}}\"\n",
      "        }\n",
      "      },\n",
      "      \"limits\": {\n",
      "        \"max_concurrent_trials\": 2,\n",
      "        \"max_total_trials\": 4,\n",
      "        \"timeout\": 3600\n",
      "      },\n",
      "      \"objective\": {\n",
      "        \"goal\": \"maximize\",\n",
      "        \"primary_metric\": \"accuracy\"\n",
      "      },\n",
      "      \"sampling_algorithm\": \"random\",\n",
      "      \"search_space\": {\n",
      "        \"learning_rate\": {\n",
      "          \"max_value\": 3.0,\n",
      "          \"min_value\": 0.1,\n",
      "          \"type\": \"uniform\"\n",
      "        }\n",
      "      },\n",
      "      \"trial\": \"azureml:azureml_anonymous:6da1cf4f-38c1-4567-8d71-707d83307646\",\n",
      "      \"type\": \"sweep\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"pipeline_inpute_and_hyper_sweep_559086\",\n",
      "  \"properties\": {\n",
      "    \"azureml.DatasetAccessMode\": \"Asset\",\n",
      "    \"azureml.DevPlatv2\": \"true\",\n",
      "    \"azureml.continue_on_failed_optional_input\": \"True\",\n",
      "    \"azureml.continue_on_step_failure\": \"True\",\n",
      "    \"azureml.defaultComputeName\": \"cpu-cluster\",\n",
      "    \"azureml.defaultDataStoreName\": \"workspaceblobstore\",\n",
      "    \"azureml.enforceRerun\": \"False\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.parameters\": \"{}\",\n",
      "    \"azureml.pipelineComponent\": \"pipelinerun\",\n",
      "    \"azureml.runsource\": \"azureml.PipelineRun\",\n",
      "    \"mlflow.source.git.branch\": \"main\",\n",
      "    \"mlflow.source.git.commit\": \"9d0744e24bfe1b0974e1fc3ab9db600f73eb94d9\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/antonslutskyms/aml-examples.git\",\n",
      "    \"runSource\": \"MFE\",\n",
      "    \"runType\": \"HTTP\"\n",
      "  },\n",
      "  \"resourceGroup\": \"SandboxML\",\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/pipeline_inpute_and_hyper_sweep_559086?wsid=/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/SandboxML/workspaces/quick-start-tutorial&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\",\n",
      "      \"type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/SandboxML/providers/Microsoft.MachineLearningServices/workspaces/quick-start-tutorial?\",\n",
      "      \"type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"settings\": {\n",
      "    \"default_compute\": \"azureml:cpu-cluster\"\n",
      "  },\n",
      "  \"status\": \"Preparing\",\n",
      "  \"type\": \"pipeline\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "!az ml job create --file sweep_pipeline.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
