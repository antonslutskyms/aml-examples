{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Inference Compute Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/conda.yml\n",
    "name: text-to-image-pipeline-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.10\n",
    "  - pip\n",
    "  - pip:\n",
    "    - azureml-evaluate-mlflow==0.0.35\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - pyarrow\n",
    "    - torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/text-to-image-pipeline-env.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: text-to-image-pipeline-cuda-env\n",
    "image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04\n",
    "conda_file: conda.yml\n",
    "description: Environment created from a Docker image plus Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml environment create --file components/text-to-image-pipeline-env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pipeline Component that will evaluate text using an LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/model_scorer.py\n",
    "\n",
    "# Read all the csvs in the data folder into a pandas dataframe\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mlflow_model\", type=str, help=\"mlflow model\")\n",
    "    parser.add_argument(\"--prompts\", type=str, help=\"path to prompts input\")\n",
    "    parser.add_argument(\"--predictions\", type=str, help=\"path to predictions output\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    print(f\"Got prompts: {args.prompts}\")\n",
    "\n",
    "    batch_df = pd.read_json(args.prompts, lines=True)\n",
    "\n",
    "    model = mlflow.pyfunc.load_model(args.mlflow_model)\n",
    "    \n",
    "    print(f\"Loaded model object: {model}\")\n",
    "\n",
    "    batch_df['input_string'] = batch_df['text'].astype(str)\n",
    "\n",
    "    batch_df = batch_df[[\"input_string\"]]\n",
    "    \n",
    "    predictions = model.predict(batch_df)\n",
    "\n",
    "    print(f\"Predictions DF: {predictions.columns}\")\n",
    "\n",
    "    print(f\"Predictions: {predictions.head()}\")\n",
    "\n",
    "    for i in range(len(predictions[0])):\n",
    "        print(\"********************************************************************\")\n",
    "        p_clean = predictions[0][i].replace('\\n', '')\n",
    "        print(f\"Input String{i}: {batch_df['input_string'][i]}\")\n",
    "        print(f\"Prediction {i}: {p_clean}\")\n",
    "        \n",
    "        ###############################################\n",
    "        # YOUR custom handling of the prediction here\n",
    "        ###############################################\n",
    "\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions[0])\n",
    "    predictions_df[\"input_string\"] = batch_df[\"input_string\"]\n",
    "\n",
    "    predictions_df.to_csv(args.predictions, index=False, header=False)\n",
    "    \n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/model_scorer.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: your_custom_model_scorer\n",
    "code: .\n",
    "command: >-\n",
    "  python model_scorer.py \n",
    "  --mlflow_model ${{inputs.mlflow_model}}\n",
    "  --prompts ${{inputs.prompts}}\n",
    "  --predictions ${{outputs.predictions}}\n",
    "inputs:\n",
    "  mlflow_model: \n",
    "    type: uri_folder\n",
    "  prompts: \n",
    "    type: uri_file\n",
    "outputs:\n",
    "  predictions:\n",
    "    type: uri_file\n",
    "environment: azureml:custom-env-1@latest\n",
    "compute: azureml:FT-Standard-NC24s-v3\n",
    "display_name: your_custom_model_scorer\n",
    "experiment_name: text-to-image-pipeline\n",
    "description: Score an MLFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml component create -f components/model_scorer.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
