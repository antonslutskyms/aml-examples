{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2aa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import __version__\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "now = datetime.now()\n",
    "output_dir = f\"./output/{now.strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac81c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.services import Service\n",
    "\n",
    "from src.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    #Service.AzureOpenAI\n",
    "    Service.OpenAI\n",
    "    #if service_settings.global_llm_service is None\n",
    "    #else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {service_settings.global_llm_service.lower()} {selectedService}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI, AsyncOpenAI, OpenAI\n",
    "from src.image_gen_text_to_image import ImageGenTextToImage\n",
    "\n",
    "# image_client = AsyncAzureOpenAI(\n",
    "#     azure_endpoint=os.getenv(\"AZURE_IMAGE_GEN_ENDPOINT\"),\n",
    "#     api_key=os.getenv(\"AZURE_IMAGE_GEN_API_KEY\"),\n",
    "#     api_version=os.getenv(\"AZURE_IMAGE_GEN_API_VERSION\"),\n",
    "# )\n",
    "image_client = AsyncOpenAI()\n",
    "sync_image_client = OpenAI()   \n",
    "\n",
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "            ai_model_id=\"gpt-4.1\"\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextToImage \n",
    "\n",
    "image_gen_service = ImageGenTextToImage (\n",
    "    async_client=image_client,\n",
    "    ai_model_id=\"gpt-image-1\",\n",
    "    service_id=\"gpt-image-1\", # Optional; for targeting specific services within Semantic Kernel\n",
    ")\n",
    "kernel.add_service(image_gen_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to convert a file to Base64\n",
    "def file_to_base64(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        # Read the file in binary mode and encode it to Base64\n",
    "        base64_encoded = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "    return base64_encoded\n",
    "\n",
    "# Example usage\n",
    "# file_path = \"image.png\"  # Replace with your file path\n",
    "# base64_string = file_to_base64(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_service = kernel.get_service(service_id=\"gpt-image-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc3ed7",
   "metadata": {},
   "source": [
    "### Generate the Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec181adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "import time\n",
    "\n",
    "seed = int(time.time())\n",
    "print(f\"Seed: {seed}\")\n",
    "execution_settings = OpenAIChatPromptExecutionSettings(seed=seed)\n",
    "\n",
    "text_gen_service = kernel.get_service(service_id=\"default\")\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "input = \"animal\"\n",
    "\n",
    "chat_history.add_message(ChatMessageContent(\n",
    "        role=AuthorRole.USER,\n",
    "        items=[\n",
    "            TextContent(text=f\"\"\"GENERATE A ONE-SENTENCE IDEA FOR A PRODUCT THAT CAN BE 3D PRINTED BY A RASIN 3D PRINTER.  \n",
    "            IT SHOULD BE A USEFUL PRODUCT LIKE A TOOTHBRUSH HOLDER OR A HOOD ORNAMENT.  IT SHOULD BE FUNNY, CREATIVE AND WIMSICAL.\n",
    "\n",
    "BE CREATIVE AND FUNNY. I WANT TO LAUGH.\n",
    "Incorporate the style suggestion, if provided: {{$style}}\n",
    "+++++\n",
    "\n",
    "{input}\n",
    "+++++\n",
    "                                \"\"\"),\n",
    "#            ImageContent(uri=f\"data:image/png;base64,{file_to_base64('./image.png')}\")\n",
    "       ]\n",
    "    ))\n",
    "\n",
    "# Get the chat completion response\n",
    "idea = await text_gen_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "idea = str(idea)\n",
    "print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384b880",
   "metadata": {},
   "source": [
    "### Generate Base Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_idea = f\"\"\"Generate a photo of a plastic 3D-printed object based on the following idea: {idea}\n",
    "The photo should be in a realistic style, with a white background and no text.\n",
    "The object should be the only thing in the image, and it should be centered in the frame.\n",
    "The object should be a 3D-printable object, and it should be in a realistic style.\n",
    "The image must not be a drawing, painting, or cartoon.\n",
    "\"\"\"\n",
    "\n",
    "image = await image_gen_service.generate_image(\n",
    "        description=print_idea, width=1024, height=1024, quality=\"auto\"\n",
    "    )\n",
    "\n",
    "image_data = base64.b64decode(image)\n",
    "\n",
    "\n",
    "base_image_path = f\"{output_dir}/image.png\"\n",
    "with open(base_image_path, \"wb\") as image_file:\n",
    "    image_file.write(image_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=base_image_path, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31295424",
   "metadata": {},
   "source": [
    "### Evaluate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "execution_settings = OpenAIChatPromptExecutionSettings()\n",
    "\n",
    "text_gen_service = kernel.get_service(service_id=\"default\")\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "base64_string = file_to_base64(f\"./{output_dir}/image.png\")\n",
    "\n",
    "# prompt = \"\"\"Evaluate the following image from the point of view of marketability and ease of 3D printing.  \n",
    "#                                 Make a one-sentense improvement suggestion.\n",
    "#                                 Only respond with the suggestion.  Do not explain the reasons for the suggestion.\n",
    "#                                 \"\"\"\n",
    "\n",
    "prompt = f\"\"\"I'm preparing this image for a 3D printing project. What objects should be removed from the image to make it more suitable for 3D printing?\"\"\" \n",
    "\n",
    "chat_history.add_message(ChatMessageContent(\n",
    "        role=AuthorRole.USER,\n",
    "        items=[\n",
    "            TextContent(text=prompt),\n",
    "            ImageContent(uri=f\"data:image/png;base64,{base64_string}\")\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "# Get the chat completion response\n",
    "eval_response = await text_gen_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "eval_response = str(eval_response)\n",
    "print(eval_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace8c50",
   "metadata": {},
   "source": [
    "### Update the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def edit_image(image, mask, prompt):\n",
    "    print(\"Editing image using OPENAI API...\")\n",
    "    result = sync_image_client.images.edit(\n",
    "        model=\"gpt-image-1\",\n",
    "        image=[\n",
    "            open(image, \"rb\"),\n",
    "        ],\n",
    "        prompt=prompt\n",
    "    )\n",
    "    print(\"Result:\", result)\n",
    "\n",
    "    return result.data[0].b64_json\n",
    "\n",
    "def edit_image_azure(image, mask, prompt):\n",
    "    url = f\"{os.getenv('AZURE_IMAGE_GEN_ENDPOINT')}/openai/deployments/{os.getenv('AZURE_IMAGE_GEN_DEPLOYMENT_NAME')}/images/edits?api-version={os.getenv('AZURE_IMAGE_GEN_API_VERSION')}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('AZURE_IMAGE_GEN_API_KEY')}\"\n",
    "    }\n",
    "\n",
    "    files = {\n",
    "        'image': ('image.png', image),\n",
    "        'mask': ('image.png', mask),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=data, files=files, headers=headers)\n",
    "\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    with open(\"response.json\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    response_js = response.json()\n",
    "    return response_js[\"data\"][0][\"b64_json\"]\n",
    "\n",
    "\n",
    "\n",
    "#image_base_64 = edit_image(open(f\"{output_dir}/image.png\", \"rb\").read(), open(\"mask.png\", \"rb\").read(), eval_response)  \n",
    "image_base_64 = edit_image(f\"{output_dir}/image.png\", \"mask.png\", \"add a vase\")  \n",
    "\n",
    "\n",
    "image_data = base64.b64decode(image_base_64)\n",
    "\n",
    "\n",
    "iter_image_path = f\"{output_dir}/image2.png\"\n",
    "with open(iter_image_path, \"wb\") as image_file:\n",
    "    image_file.write(image_data)\n",
    "\n",
    "#img = Image.open(image_path)  # nosec\n",
    "#img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90fb799",
   "metadata": {},
   "source": [
    "### Prelim. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b396bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=iter_image_path, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a28903",
   "metadata": {},
   "source": [
    "## Generate Marketing Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d996fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing1 = \"Place this object on\"\n",
    "\n",
    "marks = [\"a business desk\", \"a kitchen table\", \"a bathroom counter\", \"a living room table\", \"a coffee table\", \"a dining room table\", \"a shelf\", \"a bookcase\", \"a nightstand\", \"a dresser\"]\n",
    "\n",
    "i = -1\n",
    "for mark in marks:\n",
    "    i += 1\n",
    "    m_image_path = f\"{output_dir}/image2_{i}.png\"\n",
    "    if os.path.exists(m_image_path):\n",
    "        print(f\"File {m_image_path} already exists. Skipping...\")\n",
    "        continue\n",
    "    prompt = f\"{marketing1} {mark}.\"\n",
    "\n",
    "\n",
    "    print(prompt)\n",
    "    image_base_64 = edit_image(open(f\"{output_dir}/image2.png\", \"rb\").read(), open(\"mask2.png\", \"rb\").read(), prompt)  \n",
    "\n",
    "\n",
    "    image_data = base64.b64decode(image_base_64)\n",
    "\n",
    "\n",
    "    \n",
    "    with open(m_image_path, \"wb\") as image_file:\n",
    "        image_file.write(image_data)\n",
    "    \n",
    "    display(Image(filename=m_image_path, width=300))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70bb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b21e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = \"C:\\\\Users\\\\antonslutsky\\\\Dev\\\\aml-examples\\\\3d_objects\\\\agents\\\\output\\\\20250525141109DUE\"\n",
    "\n",
    "# # Load the image\n",
    "# image = cv2.imread(f'{base_dir}\\\\image_1.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# # Apply thresholding to create a binary image\n",
    "# _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # Find contours\n",
    "# contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Draw contours on the original image\n",
    "# image_with_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "# cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# # Display the result\n",
    "# plt.imshow(cv2.cvtColor(image_with_contours, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Contours')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # Create a directory to save the split images\n",
    "# output_dir = f\"{base_dir}/split_images\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Loop through each contour and save the corresponding region\n",
    "# for i, contour in enumerate(contours):\n",
    "#     # Get bounding box for each contour\n",
    "#     x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "#     # Extract the region of interest (ROI)\n",
    "#     roi = image[y:y+h, x:x+w]\n",
    "    \n",
    "#     # Save the ROI as a separate image\n",
    "#     output_path = os.path.join(output_dir, f\"segment_{i}.png\")\n",
    "#     cv2.imwrite(output_path, roi)\n",
    "\n",
    "# print(f\"Images saved in '{output_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(f'{base_dir}\\\\image_2.png')  # Replace 'image.jpg' with your image file path\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary image\n",
    "_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours and extract shapes\n",
    "for contour in contours:\n",
    "    # Approximate the contour to reduce the number of points\n",
    "    epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    # Draw the contour on the original image\n",
    "    cv2.drawContours(image, [approx], -1, (0, 255, 0), 3)\n",
    "\n",
    "    # Identify the shape based on the number of vertices\n",
    "    vertices = len(approx)\n",
    "    if vertices == 3:\n",
    "        shape = \"Triangle\"\n",
    "    elif vertices == 4:\n",
    "        shape = \"Rectangle/Square\"\n",
    "    elif vertices > 4:\n",
    "        shape = \"Circle\"\n",
    "    else:\n",
    "        shape = \"Unknown\"\n",
    "\n",
    "    # Get the center of the shape\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cv2.putText(image, shape, (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Shapes', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aspose-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "image = Image.open(f'{base_dir}\\\\image_2.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "bw_image = image.convert(\"L\")\n",
    "\n",
    "# Save the black and white image\n",
    "bw_image.save(f'{base_dir}\\\\image_2_gs.png')\n",
    "\n",
    "# Optionally, show the image\n",
    "bw_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94a0df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code example demonstrates how to convert PNG to SVG\n",
    "import aspose.words as aw\n",
    "\n",
    "#  Create document object\n",
    "doc = aw.Document()\n",
    "\n",
    "# Create a document builder object\n",
    "builder = aw.DocumentBuilder(doc)\n",
    "\n",
    "# Load and insert PNG image\n",
    "shape = builder.insert_image(f'{base_dir}\\\\image_blended.png')\n",
    "\n",
    "# Specify image save format as SVG\n",
    "saveOptions = aw.saving.ImageSaveOptions(aw.SaveFormat.SVG)\n",
    "\n",
    "# Save image as SVG\n",
    "shape.get_shape_renderer().save(f'{base_dir}\\\\image_blended.svg', saveOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b86d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "from potrace import Bitmap, POTRACE_TURNPOLICY_MINORITY  # `potracer` library\n",
    "\n",
    "base_dir = \".\\\\output\\\\20250525174623jZQ\"\n",
    "\n",
    "def file_to_svg(filename: str):\n",
    "    try:\n",
    "\n",
    "        image = Image.open(filename)\n",
    "    except IOError:\n",
    "        print(\"Image (%s) could not be loaded.\" % filename)\n",
    "        return\n",
    "    bm = Bitmap(image, blacklevel=0.5)\n",
    "    # bm.invert()\n",
    "    plist = bm.trace(\n",
    "        turdsize=2,\n",
    "        turnpolicy=POTRACE_TURNPOLICY_MINORITY,\n",
    "        alphamax=1,\n",
    "        opticurve=False,\n",
    "        opttolerance=0.2,\n",
    "    )\n",
    "    with open(f\"{filename}.svg\", \"w\") as fp:\n",
    "        fp.write(\n",
    "            f'''<svg version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"{image.width}\" height=\"{image.height}\" viewBox=\"0 0 {image.width} {image.height}\">''')\n",
    "        parts = []\n",
    "        for curve in plist:\n",
    "            fs = curve.start_point\n",
    "            parts.append(f\"M{fs.x},{fs.y}\")\n",
    "            for segment in curve.segments:\n",
    "                if segment.is_corner:\n",
    "                    a = segment.c\n",
    "                    b = segment.end_point\n",
    "                    parts.append(f\"L{a.x},{a.y}L{b.x},{b.y}\")\n",
    "                else:\n",
    "                    a = segment.c1\n",
    "                    b = segment.c2\n",
    "                    c = segment.end_point\n",
    "                    parts.append(f\"C{a.x},{a.y} {b.x},{b.y} {c.x},{c.y}\")\n",
    "            parts.append(\"z\")\n",
    "        fp.write(f'<path stroke=\"none\" fill=\"black\" fill-rule=\"evenodd\" d=\"{\"\".join(parts)}\"/>')\n",
    "        fp.write(\"</svg>\")\n",
    "\n",
    "file_to_svg(f'{base_dir}\\\\image_blended.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39fcd2",
   "metadata": {},
   "source": [
    "generate a jigsaw puzzle of a magical castle.  only use black, red, green and blue colors for the castle.  Ensure that all the jigsaw pieces are clearly separated by a thick white border.\n",
    "\n",
    "Generate a jigsaw puzzle of a magical castle.  \n",
    "Only use black, red, green and blue colors for the castle.  \n",
    "Ensure that all the jigsaw pieces are clearly separated by a thick white border.  \n",
    "The puzzle must have 36 clearly visible pieces separated by a white border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "base_dir = \".\\\\output\\\\20250525174623jZQ\"\n",
    "\n",
    "img = cv2.imread(f'{base_dir}\\\\image.png')\n",
    "mask = cv2.imread('puzzle_base_2.png',cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# res = cv2.bitwise_and(img,img,mask = mask)\n",
    "# res[mask==0] = 255\n",
    "\n",
    "# cv2.imwrite(f'{base_dir}\\\\image_masked_2.png', res)\n",
    "\n",
    "#cv2.imshow(\"puzzle\", res)\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "\n",
    "background = Image.open(f'{base_dir}\\\\image.png')\n",
    "overlay = Image.open('puzzle_base_masked_2.png')\n",
    "\n",
    "background = background.convert(\"RGBA\")\n",
    "overlay = overlay.convert(\"RGBA\")\n",
    "\n",
    "new_img = Image.alpha_composite(background, overlay)\n",
    "\n",
    "#new_img = Image.blend(background, overlay, 0.5)\n",
    "new_img.save(f'{base_dir}\\\\image_blended_3.png',\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b21e91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('puzzle_base_5.png')\n",
    "rgba = img.convert(\"RGBA\")\n",
    "data = rgba.getdata()\n",
    "\n",
    "target_color = (0, 0, 0, 255)\n",
    "\n",
    "new_data = []\n",
    "\n",
    "\n",
    "with open(\"data_out.txt\", \"w\") as out:\n",
    "\n",
    "    for item in data:\n",
    "        # Replace the target color with transparency\n",
    "        out.write(f\"{item}\\n\")    \n",
    "        if item[0] < 20 and item[1] < 20 and item[2] < 20:\n",
    "            new_data.append((0, 0, 0, 0))  # Fully transparent\n",
    "        else:\n",
    "            new_data.append((255, 255, 255, 255))\n",
    "\n",
    "    rgba.putdata(new_data)\n",
    "    rgba.save(\"puzzle_base_masked_2.png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb0156b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'filename'\n>  - Can't convert object to 'str' for 'filename'\n>  - Can't convert object to 'str' for 'filename'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/agent1/image1.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m base64_bytes \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;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\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerated Tree Image\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'filename'\n>  - Can't convert object to 'str' for 'filename'\n>  - Can't convert object to 'str' for 'filename'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import base64\n",
    "\n",
    "# Load the image\n",
    "image_path = './output/agent1/image1.png'\n",
    "\n",
    "base64_bytes = base64.b64decode(\"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\")\n",
    "\n",
    "image = cv2.imread(base64_bytes)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Generated Tree Image', image)\n",
    "\n",
    "# Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3a7b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def extract_puzzle_pieces(image_path, rows, cols, output_dir):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Calculate the size of each piece\n",
    "    piece_width = img_width // cols\n",
    "    piece_height = img_height // rows\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through grid and extract each piece\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Define the bounding box for the current piece\n",
    "            left = col * piece_width\n",
    "            upper = row * piece_height\n",
    "            right = left + piece_width\n",
    "            lower = upper + piece_height\n",
    "\n",
    "            # Crop the piece\n",
    "            piece = img.crop((left, upper, right, lower))\n",
    "\n",
    "            # Save the piece\n",
    "            piece_filename = os.path.join(output_dir, f\"piece_{row}_{col}.png\")\n",
    "            piece.save(piece_filename)\n",
    "\n",
    "# Parameters for the puzzle\n",
    "base_dir = \"C:\\\\Users\\\\antonslutsky\\\\Dev\\\\aml-examples\\\\3d_objects\\\\agents\\\\output\\\\pro_202505291122\"\n",
    "image_path = f\"{base_dir}\\\\image1.png\"  # Path to the input image\n",
    "output_dir = f\"{base_dir}\\\\puzzle_pieces\"  # Directory to save the pieces\n",
    "rows, cols = 4, 4  # Number of rows and columns in the puzzle grid\n",
    "\n",
    "extract_puzzle_pieces(image_path, rows, cols, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0f23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Function to extract puzzle pieces\n",
    "def extract_puzzle_pieces(image_path, rows, cols, output_dir):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Calculate the size of each piece\n",
    "    piece_width = img_width // cols\n",
    "    piece_height = img_height // rows\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through grid and extract each piece\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Define the bounding box for the current piece\n",
    "            left = col * piece_width\n",
    "            upper = row * piece_height\n",
    "            right = left + piece_width\n",
    "            lower = upper + piece_height\n",
    "\n",
    "            # Crop the piece\n",
    "            piece = img.crop((left, upper, right, lower))\n",
    "\n",
    "            # Save the piece\n",
    "            piece_filename = os.path.join(output_dir, f\"piece_{row}_{col}.png\")\n",
    "            piece.save(piece_filename)\n",
    "\n",
    "# Parameters for the puzzle\n",
    "image_path = \"./output/pro_202505291122/image1.png\"  # Path to the input image\n",
    "output_dir = \"puzzle_pieces\"  # Directory to save the pieces\n",
    "rows, cols = 4, 4  # Number of rows and columns in the puzzle grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83240ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "chat_history.add_message(ChatMessageContent(\n",
    "        role=AuthorRole.USER,\n",
    "        items=[TextContent(text=\"test\")]\n",
    "    ))\n",
    "\n",
    "output = open('chat_history.pkl', 'wb')\n",
    "\n",
    "pickle.dump(chat_history, output)\n",
    "\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb00a349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatHistory(messages=[ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='test', encoding=None)], encoding=None, finish_reason=None, status=None)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file = open('chat_history.pkl', 'rb')\n",
    "\n",
    "chat_history_loaded = pickle.load(pkl_file)\n",
    "chat_history_loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_rrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
